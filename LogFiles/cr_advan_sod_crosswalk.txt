------------------------------------------------------------------------------
      name:  <unnamed>
       log:  C:/Users/zsong98/Dropbox (Chicago Booth)/Bank Foot Traffic/code/L
> ogFiles/cr_advan_sod_crosswalk.txt
  log type:  text
 opened on:  21 Jul 2022, 15:24:37

. 
. /**************
>         Clean Data
>         ***************/
.         
.         use "$datadir/SOD/sodupdate2021.dta", clear

. * first drop all years prior to 2015 as Advan data only from 2015-2022
.         gsort year

.         drop if year < 2015
(1,897,012 observations deleted)

.         
. * check uninumbr (unique location for each branch (regardless of M&As)
.         gsort uninumbr

.         
. * drop duplicates and also keep only variables useful for matching
.         keep uninumbr-zipbr city2br sims_latitude sims_longitude namehcr 

.         * make sure lat and long are not missing
.         drop if sims_latitude == . | sims_longitude == .s
(1,593 observations deleted)

.         gduplicates drop 

Duplicates in terms of all variables

(358,791 observations deleted)

.         * keep the most recent ones 
.         bysort uninumbr: keep if _n == _N
(155,954 observations deleted)

.         save "$datadir/SOD/sod_branch_location", replace
file /Users/zsong98/Dropbox (Chicago Booth)/Bank Foot Traffic/data/source
    data/SOD/sod_branch_location.dta saved

. 
.         * the chunk below only applies to mapping when we haven't received s
> tore information 
.         * on bank names from Advan ---
.         /*
> *** clean bank ticker mapping
>         import excel "$datadir/SOD/Bank_Ticker_Mapping.xlsx", clear
>         keep B C 
>         rename (B C) (bank_name ticker_mother_company)
>         tempfile ticker_map
>         save `ticker_map'
>         
>         import delimited "$repodir/advan/t2/stores_vXV.csv", clear
> * keep only US ones 
>         keep if country_code == "US"
>         
>         * split the strings s.t. we have only the mother company for bank ti
> ckers
>         split ticker, parse("-") limit(1) gen(ticker_mother_company)
>         rename ticker_mother_company1 ticker_mother_company
>          
>         merge m:1 ticker_mother_company using "`ticker_map'"
>                 * manually check and put in bank names for those that are no
> t matched 
>                 tab ticker if _merge == 1
>                 tab ticker_mother_company if _merge == 1
>                 replace bank_name = "BB&T Corporation" if ticker == "BBT"
>                 replace bank_name = "Beacon Bancorp" if ticker == "BEACON-A-
> BCSB"
>                 replace bank_name = "BNP Paribas SA" if ticker == "BNPQF-BW"
>                 replace bank_name = "Carolina Financial Corporation" if tick
> er == "CARO-CRESCOM"
>                 replace bank_name = "Cornerstone Bancorp" if ticker == "CNBP
> "
>                 replace bank_name = "Fidelity Bank" if ticker == "FIDEL-A" 
>                 replace bank_name = "F&M Bank Corp" if ticker_mother_company
>  == "FMBM"
>                 replace bank_name = "Keycorp" if ticker == "FNFG"
>                 replace bank_name = "Gorham Savings Bank" if ticker == "GORH
> AM-A"
>                 replace bank_name = "HSBC Holdings plc" if ticker == "HBCYF"
>                 replace bank_name = "John Marshall Bancorp" if ticker == "JM
> SB"
>                 replace bank_name = "Mascoma Bank" if ticker == "MASCOMA-A"
>                 replace bank_name = "Ozark Bank" if ticker == "OZRK"
>                 replace bank_name = "Banco Santander SA" if ticker == "SAN"
>                 replace bank_name = "Suntruct Banks, Inc." if ticker == "STI
> "
>                 replace bank_name = "Toronto-Dominion Bank" if ticker == "TD
> "
>                 replace bank_name = "TSB Bank" if ticker == "TSB-A"
> 
>         drop _merge 
>         drop if bank_name == ""
>                 */      
.                 
.         * using store information sent by Advan to obtain bank names (more a
> ccurate)
.         import delimited "$datadir/advan/t2/stores_info.csv", clear
(encoding automatically selected: ISO-8859-1)
(5 vars, 48,953 obs)

.                 tempfile store_name

.                 save `store_name'
file C:\Users\zsong98\AppData\Local\Temp\ST_f64_000001.tmp saved as .dta
    format

.         import delimited "$datadir/advan/t2/stores_vXV.csv", clear
(encoding automatically selected: ISO-8859-1)
(16 vars, 55,832 obs)

.         merge 1:1 id_store using `store_name', keepusing(company_name dba)

    Result                      Number of obs
    -----------------------------------------
    Not matched                         7,489
        from master                     7,184  (_merge==1)
        from using                        305  (_merge==2)

    Matched                            48,648  (_merge==3)
    -----------------------------------------

.         
. /*      unmatched from master mainly due to foreign banks (only 3 are not)
>     Result                      Number of obs
>     -----------------------------------------
>     Not matched                         7,489
>         from master                     7,184  (_merge==1)
>         from using                        305  (_merge==2)
> 
>     Matched                            48,648  (_merge==3)
>     -----------------------------------------
> */
.         keep if _merge == 3
(7,489 observations deleted)

.         drop _merge

.         rename company_name bank_name

.         
.         * save as intermediate to investigate matching rates later on
.         save "$datadir/advan/t2/stores.dta", replace
file /Users/zsong98/Dropbox (Chicago Booth)/Bank Foot Traffic/data/source
    data/advan/t2/stores.dta saved

. /**************
>         Matching Step
>         ***************/
. 
. *** 1. joinby zip code (to generate all possible pairings within a zip code)
.         rename zip zipbr

.         * drop the strings with .0 at the end or zipcodes with form xxxxx-xx
> xx
.         replace zipbr = substr(zipbr, 1, strlen(zipbr)-2) if substr(zipbr, -
> 2, 2) == ".0"
(588 real changes made)

.         replace zipbr = substr(zipbr, 1, strlen(zipbr)-5) if substr(zipbr, -
> 5, 1) == "-"
(2,883 real changes made)

.         destring zipbr, replace
zipbr: all characters numeric; replaced as long

.         * keep only useful variables
.         keep id_store store_lat store_lon address city state zipbr bank_name
>  dba

.         joinby zipbr using "$datadir/SOD/sod_branch_location"

.         
. *** order and sort variables for better view
.         gsort zipbr id_store

.         order zipbr id_store uninumbr bank_name namehcr store_lat store_lon 
> sims_latitude sims_longitude address addresbr city citybr state stalpbr

.         
.         * drop those that are not in the same cities (wrongly recorded zip c
> odes for PR)
.         * and longitude, latitude really far apart
.         gen lat_diff = abs(store_lat-sims_latitude) 

.         gen long_diff = abs(store_lon-sims_longitude)

.         drop if (state != stalpbr) | lat_diff > 0.5 | long_diff > 0.5
(1,113 observations deleted)

.         
. *** exact matches of address
.         * clean up the address abbreviations
.         * gen rid of dots in address
.         
.         foreach x in address addresbr {
  2.                 replace `x' = subinstr(`x', ".", "", .)
  3.                 replace `x' = subinstr(`x', " + ", " ", .)
  4.                 replace `x' = subinstr(`x', "Avenue", "Av", 1)
  5.                 replace `x' = subinstr(`x', "Ave", "Av", 1)
  6.                 replace `x' = subinstr(`x', "Road", "Rd", 1) 
  7.                 replace `x' = subinstr(`x', "Drive", "Dr", 1)
  8.                 replace `x' = subinstr(`x', "Place", "Pl", 1)
  9.                 replace `x' = subinstr(`x', "Boulevard", "Blvd", 1)
 10.                 replace `x' = subinstr(`x', "Route", "Rt", 1)
 11.                 replace `x' = subinstr(`x', "Highway", "Hwy", 1)
 12.                 replace `x' = subinstr(`x', "Street", "St", 1)
 13.                 replace `x' = subinstr(`x', "Suite", "Ste", 1)
 14.                 replace `x' = subinstr(`x', "Court", "CT", 1)
 15.                 replace `x' = subinstr(`x', "Circle", "CIR", 1)
 16.                 replace `x' = subinstr(`x', "Plaza", "Plz", 1)
 17.                 replace `x' = subinstr(`x', "Lane", "Ln", 1)
 18.                 replace `x' = subinstr(`x', "Parkway", "Pkwy", 1)
 19.                 replace `x' = subinstr(`x', "Floor", "Fl", 1)
 20.                 replace `x' = subinstr(`x', "Turnpike", "Tpke", 1)
 21.                 replace `x' = subinstr(`x', "Trail", "Tr", 1)
 22.                 * replace the North, South, West, East (direction ones
.                 replace `x' = subinstr(`x', " N ", " North ", 1)
 23.                 replace `x' = subinstr(`x', " S ", " South ", 1)
 24.                 replace `x' = subinstr(`x', " W ", " West ", 1)
 25.                 replace `x' = subinstr(`x', " E ", " East ", 1)
 26.                 replace `x' = subinstr(`x', " N", " North", 1) if substr(
> `x', -2, 2) == " N"
 27.                 replace `x' = subinstr(`x', " S", " South", 1) if substr(
> `x', -2, 2) == " S"
 28.                 replace `x' = subinstr(`x', " W", " West", 1) if substr(`
> x', -2, 2) == " W"
 29.                 replace `x' = subinstr(`x', " E", " East", 1) if substr(`
> x', -2, 2) == " E"
 30.                 * replace numbers (first-tenth)
.                 replace `x' = subinstr(`x', "Fisrt", "1st", 1)
 31.                 replace `x' = subinstr(`x', "Second", "2nd", 1)
 32.                 replace `x' = subinstr(`x', "Third", "3rd", 1)
 33.                 replace `x' = subinstr(`x', "Fourth", "4th", 1) 
 34.                 replace `x' = subinstr(`x', "Fifth", "5th", 1)
 35.                 replace `x' = subinstr(`x', "Sixth", "6th", 1)  
 36.                 replace `x' = subinstr(`x', "Seventh", "7th", 1)
 37.                 replace `x' = subinstr(`x', "Eighth", "8th", 1) 
 38.                 replace `x' = subinstr(`x', "Ninth", "9th", 1)  
 39.                 replace `x' = subinstr(`x', "Tenth", "10th", 1)
 40.                 replace `x' = subinstr(`x', "One", "1", 1)
 41.                 replace `x' = subinstr(`x', "Two", "2", 1)
 42.                 replace `x' = subinstr(`x', "Three", "3", 1)    
 43.                 replace `x' = subinstr(`x', "Four", "4", 1)     
 44.                 replace `x' = subinstr(`x', "Five", "5", 1)     
 45.                 replace `x' = subinstr(`x', "Six", "6", 1)      
 46.                 replace `x' = subinstr(`x', "Seven", "7", 1)    
 47.                 replace `x' = subinstr(`x', "Eight", "8", 1)    
 48.                 replace `x' = subinstr(`x', "Nine", "9", 1)     
 49.                 replace `x' = subinstr(`x', "Ten", "10", 1)     
 50.         }
(24,801 real changes made)
(0 real changes made)
(38,774 real changes made)
(63,749 real changes made)
(49,038 real changes made)
(13,378 real changes made)
(1,471 real changes made)
(16,986 real changes made)
(6,587 real changes made)
(15,035 real changes made)
(57,712 real changes made)
(7,302 real changes made)
(1,830 real changes made)
(1,461 real changes made)
(3,025 real changes made)
(2,372 real changes made)
(5,179 real changes made)
(1,906 real changes made)
(1,114 real changes made)
(2,323 real changes made)
(31,805 real changes made)
(31,144 real changes made)
(33,233 real changes made)
(29,715 real changes made)
(3,996 real changes made)
(4,174 real changes made)
(2,735 real changes made)
(3,091 real changes made)
(0 real changes made)
(934 real changes made)
(991 real changes made)
(432 real changes made)
(847 real changes made)
(306 real changes made)
(258 real changes made)
(177 real changes made)
(172 real changes made)
(92 real changes made)
(785 real changes made)
(296 real changes made)
(57 real changes made)
(69 real changes made)
(114 real changes made)
(316 real changes made)
(151 real changes made)
(45 real changes made)
(64 real changes made)
(261 real changes made)
(39,557 real changes made)
(7 real changes made)
(85,296 real changes made)
(16,700 real changes made)
(103,416 real changes made)
(30,795 real changes made)
(2,577 real changes made)
(38,659 real changes made)
(6,721 real changes made)
(22,349 real changes made)
(121,844 real changes made)
(31,514 real changes made)
(2,251 real changes made)
(2,246 real changes made)
(3,633 real changes made)
(5,116 real changes made)
(12,801 real changes made)
(1,637 real changes made)
(2,084 real changes made)
(2,825 real changes made)
(11,757 real changes made)
(10,226 real changes made)
(11,198 real changes made)
(10,360 real changes made)
(1,362 real changes made)
(1,387 real changes made)
(1,040 real changes made)
(1,045 real changes made)
(0 real changes made)
(1,678 real changes made)
(2,840 real changes made)
(1,133 real changes made)
(1,954 real changes made)
(561 real changes made)
(550 real changes made)
(387 real changes made)
(358 real changes made)
(253 real changes made)
(1,927 real changes made)
(378 real changes made)
(129 real changes made)
(151 real changes made)
(151 real changes made)
(434 real changes made)
(184 real changes made)
(109 real changes made)
(85 real changes made)
(288 real changes made)

. 
.         * change all strings to lowercase
.         foreach str in address addresbr bank_name dba namehcr namefull {
  2.                 replace `str' = strlower(`str')
  3.         }
(570,841 real changes made)
(570,851 real changes made)
(570,870 real changes made)
(570,870 real changes made)
(539,143 real changes made)
(570,836 real changes made)

.         
.         gen exact = 1 if address == addresbr
(539,634 missing values generated)

.                 
.         * keep those that have been exactly matched in a tempfile 
.         preserve

.                 keep if exact == 1
(539,634 observations deleted)

.                 *** note that the exact matches have duplicates (one id_stor
> e matched to multiple branches)
.                 replace namefull = subinstr(namefull, ", national associatio
> n", "", .)  
(18,381 real changes made)

.                 ustrdist bank_name namehcr, gen(banknamedist1)

.                 ustrdist bank_name namefull, gen(banknamedist2)

.                 ustrdist dba namehcr, gen(banknamedist3)

.                 ustrdist dba namefull, gen(banknamedist4)

.                 egen bankname_dist = rowmin(banknamedist1 banknamedist2 bank
> namedist3 banknamedist4)

.                 drop banknamedist*

.                 * within exact exactly matched address, keep only the one br
> anch that has the closest name to the bank_name in case of duplicates (in ca
> se where there is no duplicates, the name different is ok as there are merge
> rs and acquisitions and change of local branch name sometimes)
.                 bysort id_store (bankname_dist): egen bankname_dist_min = mi
> n(bankname_dist)

.                 keep if bankname_dist_min == bankname_dist
(418 observations deleted)

.                 * do the same for each unique uninumbr as well
.                 drop bankname_dist_min

.                 bysort uninumbr (bankname_dist): egen bankname_dist_min = mi
> n(bankname_dist)

.                 keep if bankname_dist_min == bankname_dist
(632 observations deleted)

.                 tempfile exact

.                 save `exact', replace
(file C:\Users\zsong98\AppData\Local\Temp\ST_f64_000003.tmp not found)
file C:\Users\zsong98\AppData\Local\Temp\ST_f64_000003.tmp saved as .dta
    format

.         restore

.         * and drop the id_stores that have been exactly matched
.         bysort id_store: egen exact_matched = max(exact) 
(205,453 missing values generated)

.         sum lat_diff long_diff if exact == 1 // get a sense of how close (la
> t-long) the exact matches are 

    Variable |        Obs        Mean    Std. dev.       Min        Max
-------------+---------------------------------------------------------
    lat_diff |     31,236    .0014153    .0079852          0   .3920059
   long_diff |     31,236      .00173    .0092534          0    .495491

.         drop if exact_matched == 1
(365,417 observations deleted)

.         
. *** fuzzy matches based on distances
.         ustrdist address addresbr, gen(addresdist)

.         gsort zipbr id_store addresdist

.         order addresdist address addresbr bank_name namehcr namefull *_diff

.         
.         * keep only Levenstein distances smaller than 10 ones 
.         drop if addresdist > 10 
(145,069 observations deleted)

.         
.         /* 1. within each zip-id_store combinations, first keep the ones wit
> h Levenstein distances <= 2 
>         gen fuzzy_dist_1 = 1 if addresdist == 1
>         * save the above data 
>         preserve
>                 keep if fuzzy_dist_1 == 1
>                 tempfile fuzzy_dist_1
>                 save `fuzzy_dist_1', replace
>         restore
>         * and drop the id_stores that have been exactly matched
>         bysort id_store: egen fuzzy_dist_1_matched = max(fuzzy_dist_1) 
>         sum lat_diff long_diff if fuzzy_dist_1 == 1 // get a sense of how cl
> ose the fuzzy dist 1 matches are 
>         drop if fuzzy_dist_1_matched == 1
>         */
.         // note that for the exact matches, the lat-long differences are aro
> und 0.0015 
. 
.         * 1. get string distances between bank_name (advan) and namehcr/name
> full (SOD)
.                 replace namefull = subinstr(namefull, ", national associatio
> n", "", .)  
(25,376 real changes made)

.                 ustrdist bank_name namehcr, gen(banknamedist1)

.                 ustrdist bank_name namefull, gen(banknamedist2)

.                 ustrdist dba namehcr, gen(banknamedist3)

.                 ustrdist dba namefull, gen(banknamedist4)

.                 egen bankname_dist = rowmin(banknamedist1 banknamedist2 bank
> namedist3 banknamedist4)

.                 drop banknamedist*

.                 * manually check for a threshold that shows that bank names 
> are the same
.                 gsort zipbr id_store bankname_dist

.                 * also keep only the closest bank names for each unique stor
> e 
.                 bysort id_store (bankname_dist): keep if _n == 1
(45,995 observations deleted)

.                 drop if bankname_dist > 5               
(6,648 observations deleted)

.         
.         * 2. now check the lat-long coordinates and addresses to see if we h
> ave good matches    
.                 drop if addresdist > 5
(3,064 observations deleted)

.                 drop if lat_diff > 0.001 | long_diff > 0.001 // here we are 
> really conservative as there are also pretty good matchings if we take lat/l
> ong_diff to be around 0.002. 
(1,983 observations deleted)

.                 gen fuzzy = 1 

. 
. *** merge exact and fuzzy match results together
.         append using "`exact'"

.         
.         * order and keep variables 
.         keep bank_name name* address addresbr zipbr id_store uninumbr store_
> lat store_lon sims_* city state exact fuzzy 

.         replace exact = 0 if exact >=.
(2,694 real changes made)

.         replace fuzzy = 0 if fuzzy >=.
(30,186 real changes made)

.         
.         order id_store uninumbr 

.                 
.         * within each duplicated match from uninumbr to id_store, keep only 
> the exact matched ones
.         bysort uninumbr (exact): keep if _n == 1
(191 observations deleted)

.         * note that there are still a few duplicates due to duplicated unibr
> anch 
.         duplicates tag id_store, gen(dup)

Duplicates in terms of id_store

.         tab dup  

        dup |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |     32,497       99.41       99.41
          1 |        186        0.57       99.98
          2 |          6        0.02      100.00
------------+-----------------------------------
      Total |     32,689      100.00

.         * but looking over the duplicates shows that id_store is correctly m
> atched
.         * to each branch --
.         
. save "$datadir/advan_sod_crosswalk", replace
file /Users/zsong98/Dropbox (Chicago Booth)/Bank Foot Traffic/data/source
    data/advan_sod_crosswalk.dta saved

. 
. /**************
>         Histograms
>         ***************/
.         
. *** matching rates of banks in the Advan sample already
.         use "$datadir/advan_sod_crosswalk", clear

.         duplicates drop id_store, force

Duplicates in terms of id_store

(97 observations deleted)

.         merge 1:1 id_store using "$datadir/advan/t2/stores.dta"

    Result                      Number of obs
    -----------------------------------------
    Not matched                        16,056
        from master                         0  (_merge==1)
        from using                     16,056  (_merge==2)

    Matched                            32,592  (_merge==3)
    -----------------------------------------

.         replace bank_name = strlower(bank_name)
(16,056 real changes made)

.         egen matched = rowmax(exact fuzzy)
(16,056 missing values generated)

.         bysort bank_name: egen match_total = sum(matched)

.         bysort bank_name: gen match_rate = match_total / _N

.         * keep only those with matched total > 10 for plot
.         * keep if match_total > 10
.         * plot
.         graph hbar match_rate, over(bank_name, sort(1) descending label(labs
> ize(*0.3))) ytitle("Match Rate of Banks from Advan Sample")

.         graph export "$figdir/advan_match_rate.pdf", replace
file /Users/zsong98/Dropbox (Chicago Booth)/Bank Foot
    Traffic/output/figures/zs/advan_match_rate.pdf saved as PDF format

.         graph hbar match_total, over(bank_name, sort(1) descending label(lab
> size(*0.3))) ytitle("Total Matched Branches from Advan Sample")

.         graph export "$figdir/advan_match_total.pdf", replace
file /Users/zsong98/Dropbox (Chicago Booth)/Bank Foot
    Traffic/output/figures/zs/advan_match_total.pdf saved as PDF format

.         
. *** matching rates of banks from the SOD data
.         use "$datadir/advan_sod_crosswalk", clear

.         merge 1:1 uninumbr using "$datadir/SOD/sod_branch_location"

    Result                      Number of obs
    -----------------------------------------
    Not matched                        67,199
        from master                         0  (_merge==1)
        from using                     67,199  (_merge==2)

    Matched                            32,689  (_merge==3)
    -----------------------------------------

.         * standardize the newly merged full name of banks
.         replace namefull = strlower(namefull)
(67,196 real changes made)

.         replace namefull = subinstr(namefull, ", national association", "", 
> .)  
(11,781 real changes made)

.         egen matched = rowmax(exact fuzzy)
(67,199 missing values generated)

.         bysort namefull: egen match_total = sum(matched)

.         bysort namefull: gen match_rate = match_total / _N

.         * keep only those that have at least positive match rates 
.         drop if match_rate == 0
(42,192 observations deleted)

.         * keep only those with matched total > 15 for plot
.         keep if match_total > 15
(11,727 observations deleted)

.         * plot
.         graph hbar match_rate, over(namefull, sort(1) descending label(labsi
> ze(*0.30))) ytitle("Match Rate of Banks from SOD (only those with more than 
> 15 matches)")

.         graph export "$figdir/sod_match_rate.pdf", replace
file /Users/zsong98/Dropbox (Chicago Booth)/Bank Foot
    Traffic/output/figures/zs/sod_match_rate.pdf saved as PDF format

.         graph hbar match_total, over(namefull, sort(1) descending label(labs
> ize(*0.30))) ytitle("Total Matched Branches from SOD (only those with more t
> han 15 matches)")

.         graph export "$figdir/sod_match_total.pdf", replace
file /Users/zsong98/Dropbox (Chicago Booth)/Bank Foot
    Traffic/output/figures/zs/sod_match_total.pdf saved as PDF format

.         
. *** get unmatched sample for inspection 
.         use "$datadir/advan_sod_crosswalk", clear

.         duplicates drop id_store, force

Duplicates in terms of id_store

(97 observations deleted)

.         merge 1:1 id_store using "$datadir/advan/t2/stores.dta"

    Result                      Number of obs
    -----------------------------------------
    Not matched                        16,056
        from master                         0  (_merge==1)
        from using                     16,056  (_merge==2)

    Matched                            32,592  (_merge==3)
    -----------------------------------------

.         keep if _merge == 2
(32,592 observations deleted)

.         drop _merge 

.         keep id_store address bank_name store_* city state ticker-country_co
> de dba

.         save "$datadir/unmatched_advan_branches.dta", replace
file /Users/zsong98/Dropbox (Chicago Booth)/Bank Foot Traffic/data/source
    data/unmatched_advan_branches.dta saved

. ****************************************************************************
> ****
. capture log close
