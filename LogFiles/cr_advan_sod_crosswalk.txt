------------------------------------------------------------------------------
      name:  <unnamed>
       log:  C:/Users/zsong98/Dropbox (Chicago Booth)/Bank Foot Traffic/code/L
> ogFiles/cr_advan_sod_crosswalk.txt
  log type:  text
 opened on:   4 Dec 2022, 16:47:27

. 
. /**************
>         Clean Data
>         ***************/
.         
.         use "$datadir/SOD/sodupdate2021.dta", clear

. * first drop all years prior to 2015 as Advan data only from 2015-2022
.         gsort year

.         drop if year < 2015
(1,897,012 observations deleted)

.         
. * check uninumbr (unique location for each branch (regardless of M&As)
.         gsort uninumbr

.         
. * drop duplicates and also keep only variables useful for matching
.         keep uninumbr-zipbr city2br sims_latitude sims_longitude namehcr 

.         * make sure lat and long are not missing
.         drop if sims_latitude == . | sims_longitude == .s
(1,593 observations deleted)

.         gduplicates drop 

Duplicates in terms of all variables

(358,791 observations deleted)

.         * keep the most recent ones 
.         bysort uninumbr: keep if _n == _N
(155,954 observations deleted)

.         save "$datadir/SOD/sod_branch_location", replace
file /Users/zsong98/Dropbox (Chicago Booth)/Bank Foot Traffic/data/source
    data/SOD/sod_branch_location.dta saved

. 
.         * the chunk below only applies to mapping when we haven't received s
> tore information 
.         * on bank names from Advan ---
.         /*
> *** clean bank ticker mapping
>         import excel "$datadir/SOD/Bank_Ticker_Mapping.xlsx", clear
>         keep B C 
>         rename (B C) (bank_name ticker_mother_company)
>         tempfile ticker_map
>         save `ticker_map'
>         
>         import delimited "$repodir/advan/t2/stores_vXV.csv", clear
> * keep only US ones 
>         keep if country_code == "US"
>         
>         * split the strings s.t. we have only the mother company for bank ti
> ckers
>         split ticker, parse("-") limit(1) gen(ticker_mother_company)
>         rename ticker_mother_company1 ticker_mother_company
>          
>         merge m:1 ticker_mother_company using "`ticker_map'"
>                 * manually check and put in bank names for those that are no
> t matched 
>                 tab ticker if _merge == 1
>                 tab ticker_mother_company if _merge == 1
>                 replace bank_name = "BB&T Corporation" if ticker == "BBT"
>                 replace bank_name = "Beacon Bancorp" if ticker == "BEACON-A-
> BCSB"
>                 replace bank_name = "BNP Paribas SA" if ticker == "BNPQF-BW"
>                 replace bank_name = "Carolina Financial Corporation" if tick
> er == "CARO-CRESCOM"
>                 replace bank_name = "Cornerstone Bancorp" if ticker == "CNBP
> "
>                 replace bank_name = "Fidelity Bank" if ticker == "FIDEL-A" 
>                 replace bank_name = "F&M Bank Corp" if ticker_mother_company
>  == "FMBM"
>                 replace bank_name = "Keycorp" if ticker == "FNFG"
>                 replace bank_name = "Gorham Savings Bank" if ticker == "GORH
> AM-A"
>                 replace bank_name = "HSBC Holdings plc" if ticker == "HBCYF"
>                 replace bank_name = "John Marshall Bancorp" if ticker == "JM
> SB"
>                 replace bank_name = "Mascoma Bank" if ticker == "MASCOMA-A"
>                 replace bank_name = "Ozark Bank" if ticker == "OZRK"
>                 replace bank_name = "Banco Santander SA" if ticker == "SAN"
>                 replace bank_name = "Suntruct Banks, Inc." if ticker == "STI
> "
>                 replace bank_name = "Toronto-Dominion Bank" if ticker == "TD
> "
>                 replace bank_name = "TSB Bank" if ticker == "TSB-A"
> 
>         drop _merge 
>         drop if bank_name == ""
>                 */      
.                 
.         * using store information sent by Advan to obtain bank names (more a
> ccurate)
.         import delimited "$datadir/advan/t2/stores_info.csv", clear
(encoding automatically selected: ISO-8859-1)
(5 vars, 48,953 obs)

.                 tempfile store_name

.                 save `store_name'
file C:\Users\zsong98\AppData\Local\Temp\ST_462c_000001.tmp saved as .dta
    format

.         import delimited "$datadir/advan/t2/stores_vXV.csv", clear
(encoding automatically selected: ISO-8859-1)
(16 vars, 55,832 obs)

.         merge 1:1 id_store using `store_name', keepusing(company_name dba)

    Result                      Number of obs
    -----------------------------------------
    Not matched                         7,489
        from master                     7,184  (_merge==1)
        from using                        305  (_merge==2)

    Matched                            48,648  (_merge==3)
    -----------------------------------------

.         
. /*      unmatched from master mainly due to foreign banks (only 3 are not)
>     Result                      Number of obs
>     -----------------------------------------
>     Not matched                         7,489
>         from master                     7,184  (_merge==1)
>         from using                        305  (_merge==2)
> 
>     Matched                            48,648  (_merge==3)
>     -----------------------------------------
> */
.         keep if _merge == 3
(7,489 observations deleted)

.         drop _merge

.         rename company_name bank_name

.         
.         * save as intermediate to investigate matching rates later on
.         save "$datadir/advan/t2/stores.dta", replace
file /Users/zsong98/Dropbox (Chicago Booth)/Bank Foot Traffic/data/source
    data/advan/t2/stores.dta saved

. /**************
>         Matching Step
>         ***************/
. 
. *** 1. joinby zip code (to generate all possible pairings within a zip code)
.         * drop the strings with .0 at the end or zipcodes with form xxxxx-xx
> xx
.         replace zip = substr(zip, 1, strlen(zip)-2) if substr(zip, -2, 2) ==
>  ".0"
(588 real changes made)

.         replace zip = substr(zip, 1, strlen(zip)-5) if substr(zip, -5, 1) ==
>  "-"
(2,883 real changes made)

.         rename zip zipbr

.         destring zipbr, replace
zipbr: all characters numeric; replaced as long

.         * keep only useful variables
.         keep id_store store_lat store_lon address city state zipbr bank_name
>  dba

.         joinby zipbr using "$datadir/SOD/sod_branch_location"

.         
. *** order and sort variables for better view
.         gsort zipbr id_store

.         order zipbr id_store uninumbr bank_name namehcr store_lat store_lon 
> sims_latitude sims_longitude address addresbr city citybr state stalpbr

.         
.         * drop those that are not in the same cities (wrongly recorded zip c
> odes for PR)
.         * and longitude, latitude really far apart
.         gen lat_diff = abs(store_lat-sims_latitude) 

.         gen long_diff = abs(store_lon-sims_longitude)

.         drop if (state != stalpbr) | lat_diff > 0.5 | long_diff > 0.5
(1,085 observations deleted)

.         
. *** exact matches of address
.         * clean up the address abbreviations
.         * gen rid of dots in address
.         
.         foreach x in address addresbr {
  2.                 replace `x' = subinstr(`x', ".", "", .)
  3.                 replace `x' = subinstr(`x', " + ", " ", .)
  4.                 replace `x' = subinstr(`x', "Avenue", "Av", 1)
  5.                 replace `x' = subinstr(`x', "Ave", "Av", 1)
  6.                 replace `x' = subinstr(`x', "Road", "Rd", 1) 
  7.                 replace `x' = subinstr(`x', "Drive", "Dr", 1)
  8.                 replace `x' = subinstr(`x', "Place", "Pl", 1)
  9.                 replace `x' = subinstr(`x', "Boulevard", "Blvd", 1)
 10.                 replace `x' = subinstr(`x', "Route", "Rt", 1)
 11.                 replace `x' = subinstr(`x', "Highway", "Hwy", 1)
 12.                 replace `x' = subinstr(`x', "Street", "St", 1)
 13.                 replace `x' = subinstr(`x', "Suite", "Ste", 1)
 14.                 replace `x' = subinstr(`x', "Court", "CT", 1)
 15.                 replace `x' = subinstr(`x', "Circle", "CIR", 1)
 16.                 replace `x' = subinstr(`x', "Plaza", "Plz", 1)
 17.                 replace `x' = subinstr(`x', "Lane", "Ln", 1)
 18.                 replace `x' = subinstr(`x', "Parkway", "Pkwy", 1)
 19.                 replace `x' = subinstr(`x', "Floor", "Fl", 1)
 20.                 replace `x' = subinstr(`x', "Turnpike", "Tpke", 1)
 21.                 replace `x' = subinstr(`x', "Trail", "Tr", 1)
 22.                 * replace the North, South, West, East (direction ones
.                 replace `x' = subinstr(`x', " N ", " North ", 1)
 23.                 replace `x' = subinstr(`x', " S ", " South ", 1)
 24.                 replace `x' = subinstr(`x', " W ", " West ", 1)
 25.                 replace `x' = subinstr(`x', " E ", " East ", 1)
 26.                 replace `x' = subinstr(`x', " N", " North", 1) if substr(
> `x', -2, 2) == " N"
 27.                 replace `x' = subinstr(`x', " S", " South", 1) if substr(
> `x', -2, 2) == " S"
 28.                 replace `x' = subinstr(`x', " W", " West", 1) if substr(`
> x', -2, 2) == " W"
 29.                 replace `x' = subinstr(`x', " E", " East", 1) if substr(`
> x', -2, 2) == " E"
 30.                 * replace numbers (first-tenth)
.                 replace `x' = subinstr(`x', "Fisrt", "1st", 1)
 31.                 replace `x' = subinstr(`x', "Second", "2nd", 1)
 32.                 replace `x' = subinstr(`x', "Third", "3rd", 1)
 33.                 replace `x' = subinstr(`x', "Fourth", "4th", 1) 
 34.                 replace `x' = subinstr(`x', "Fifth", "5th", 1)
 35.                 replace `x' = subinstr(`x', "Sixth", "6th", 1)  
 36.                 replace `x' = subinstr(`x', "Seventh", "7th", 1)
 37.                 replace `x' = subinstr(`x', "Eighth", "8th", 1) 
 38.                 replace `x' = subinstr(`x', "Ninth", "9th", 1)  
 39.                 replace `x' = subinstr(`x', "Tenth", "10th", 1)
 40.                 replace `x' = subinstr(`x', "One", "1", 1)
 41.                 replace `x' = subinstr(`x', "Two", "2", 1)
 42.                 replace `x' = subinstr(`x', "Three", "3", 1)    
 43.                 replace `x' = subinstr(`x', "Four", "4", 1)     
 44.                 replace `x' = subinstr(`x', "Five", "5", 1)     
 45.                 replace `x' = subinstr(`x', "Six", "6", 1)      
 46.                 replace `x' = subinstr(`x', "Seven", "7", 1)    
 47.                 replace `x' = subinstr(`x', "Eight", "8", 1)    
 48.                 replace `x' = subinstr(`x', "Nine", "9", 1)     
 49.                 replace `x' = subinstr(`x', "Ten", "10", 1)     
 50.         }
(24,798 real changes made)
(0 real changes made)
(38,820 real changes made)
(63,827 real changes made)
(49,039 real changes made)
(13,397 real changes made)
(1,472 real changes made)
(17,027 real changes made)
(6,549 real changes made)
(15,006 real changes made)
(57,751 real changes made)
(7,299 real changes made)
(1,827 real changes made)
(1,455 real changes made)
(3,021 real changes made)
(2,376 real changes made)
(5,177 real changes made)
(1,900 real changes made)
(1,107 real changes made)
(2,321 real changes made)
(31,775 real changes made)
(31,149 real changes made)
(33,208 real changes made)
(29,752 real changes made)
(3,990 real changes made)
(4,182 real changes made)
(2,730 real changes made)
(3,077 real changes made)
(0 real changes made)
(936 real changes made)
(1,012 real changes made)
(426 real changes made)
(842 real changes made)
(307 real changes made)
(260 real changes made)
(168 real changes made)
(165 real changes made)
(93 real changes made)
(786 real changes made)
(294 real changes made)
(55 real changes made)
(69 real changes made)
(114 real changes made)
(310 real changes made)
(150 real changes made)
(46 real changes made)
(63 real changes made)
(265 real changes made)
(39,681 real changes made)
(7 real changes made)
(85,275 real changes made)
(16,944 real changes made)
(103,436 real changes made)
(30,860 real changes made)
(2,613 real changes made)
(38,518 real changes made)
(6,705 real changes made)
(22,296 real changes made)
(121,992 real changes made)
(31,349 real changes made)
(2,259 real changes made)
(2,180 real changes made)
(3,624 real changes made)
(5,153 real changes made)
(12,751 real changes made)
(1,589 real changes made)
(2,035 real changes made)
(2,810 real changes made)
(11,720 real changes made)
(10,313 real changes made)
(11,243 real changes made)
(10,314 real changes made)
(1,342 real changes made)
(1,423 real changes made)
(1,075 real changes made)
(1,046 real changes made)
(0 real changes made)
(1,700 real changes made)
(2,867 real changes made)
(1,123 real changes made)
(2,037 real changes made)
(554 real changes made)
(595 real changes made)
(369 real changes made)
(355 real changes made)
(254 real changes made)
(1,984 real changes made)
(348 real changes made)
(129 real changes made)
(142 real changes made)
(145 real changes made)
(421 real changes made)
(191 real changes made)
(93 real changes made)
(78 real changes made)
(297 real changes made)

. 
.         * change all strings to lowercase
.         foreach str in address addresbr bank_name dba namehcr namefull {
  2.                 replace `str' = strlower(`str')
  3.         }
(570,950 real changes made)
(570,955 real changes made)
(570,978 real changes made)
(570,978 real changes made)
(539,011 real changes made)
(570,941 real changes made)

.         
.         gen exact = 1 if address == addresbr
(539,727 missing values generated)

.                 
.         * keep those that have been exactly matched in a tempfile 
.         preserve

.                 keep if exact == 1
(539,727 observations deleted)

.                 *** note that the exact matches have duplicates (one id_stor
> e matched to multiple branches)
.                 replace namefull = subinstr(namefull, ", national associatio
> n", "", .)  
(18,315 real changes made)

.                 ustrdist bank_name namehcr, gen(banknamedist1)

.                 ustrdist bank_name namefull, gen(banknamedist2)

.                 ustrdist dba namehcr, gen(banknamedist3)

.                 ustrdist dba namefull, gen(banknamedist4)

.                 egen bankname_dist = rowmin(banknamedist1 banknamedist2 bank
> namedist3 banknamedist4)

.                 drop banknamedist*

.                 * within exact exactly matched address, keep only the one br
> anch that has the closest name to the bank_name in case of duplicates (in ca
> se where there is no duplicates, the name different is ok as there are merge
> rs and acquisitions and change of local branch name sometimes)
.                 bysort id_store (bankname_dist): egen bankname_dist_min = mi
> n(bankname_dist)

.                 keep if bankname_dist_min == bankname_dist
(422 observations deleted)

.                 * do the same for each unique uninumbr as well
.                 drop bankname_dist_min

.                 bysort uninumbr (bankname_dist): egen bankname_dist_min = mi
> n(bankname_dist)

.                 keep if bankname_dist_min == bankname_dist
(625 observations deleted)

.                 tempfile exact

.                 save `exact', replace
(file C:\Users\zsong98\AppData\Local\Temp\ST_462c_000003.tmp not found)
file C:\Users\zsong98\AppData\Local\Temp\ST_462c_000003.tmp saved as .dta
    format

.         restore

.         * and drop the id_stores that have been exactly matched
.         bysort id_store: egen exact_matched = max(exact) 
(205,645 missing values generated)

.         sum lat_diff long_diff if exact == 1 // get a sense of how close (la
> t-long) the exact matches are 

    Variable |        Obs        Mean    Std. dev.       Min        Max
-------------+---------------------------------------------------------
    lat_diff |     31,251    .0014527    .0085049          0   .3920288
   long_diff |     31,251    .0017878    .0103116          0   .4954987

.         drop if exact_matched == 1
(365,333 observations deleted)

.         
. *** fuzzy matches based on distances
.         ustrdist address addresbr, gen(addresdist)

.         gsort zipbr id_store addresdist

.         order addresdist address addresbr bank_name namehcr namefull *_diff

.         
.         * keep only Levenstein distances smaller than 10 ones 
.         drop if addresdist > 10 
(145,413 observations deleted)

.         
.         /* 1. within each zip-id_store combinations, first keep the ones wit
> h Levenstein distances <= 2 
>         gen fuzzy_dist_1 = 1 if addresdist == 1
>         * save the above data 
>         preserve
>                 keep if fuzzy_dist_1 == 1
>                 tempfile fuzzy_dist_1
>                 save `fuzzy_dist_1', replace
>         restore
>         * and drop the id_stores that have been exactly matched
>         bysort id_store: egen fuzzy_dist_1_matched = max(fuzzy_dist_1) 
>         sum lat_diff long_diff if fuzzy_dist_1 == 1 // get a sense of how cl
> ose the fuzzy dist 1 matches are 
>         drop if fuzzy_dist_1_matched == 1
>         */
.         // note that for the exact matches, the lat-long differences are aro
> und 0.0015 
. 
.         * 1. get string distances between bank_name (advan) and namehcr/name
> full (SOD)
.                 replace namefull = subinstr(namefull, ", national associatio
> n", "", .)  
(25,286 real changes made)

.                 ustrdist bank_name namehcr, gen(banknamedist1)

.                 ustrdist bank_name namefull, gen(banknamedist2)

.                 ustrdist dba namehcr, gen(banknamedist3)

.                 ustrdist dba namefull, gen(banknamedist4)

.                 egen bankname_dist = rowmin(banknamedist1 banknamedist2 bank
> namedist3 banknamedist4)

.                 drop banknamedist*

.                 * manually check for a threshold that shows that bank names 
> are the same
.                 gsort zipbr id_store bankname_dist

.                 * also keep only the closest bank names for each unique stor
> e 
.                 bysort id_store (bankname_dist): keep if _n == 1
(45,850 observations deleted)

.                 drop if bankname_dist > 5               
(6,638 observations deleted)

.         
.         * 2. now check the lat-long coordinates and addresses to see if we h
> ave good matches    
.                 drop if addresdist > 5
(3,034 observations deleted)

.                 drop if lat_diff > 0.001 | long_diff > 0.001 // here we are 
> really conservative as there are also pretty good matchings if we take lat/l
> ong_diff to be around 0.002. 
(1,993 observations deleted)

.                 gen fuzzy = 1 

. 
. *** merge exact and fuzzy match results together
.         append using "`exact'"

.         
.         * order and keep variables 
.         keep bank_name name* address addresbr zipbr id_store uninumbr store_
> lat store_lon sims_* city state exact fuzzy 

.         replace exact = 0 if exact >=.
(2,717 real changes made)

.         replace fuzzy = 0 if fuzzy >=.
(30,204 real changes made)

.         
.         order id_store uninumbr 

.                 
.         save "$datadir/advan_sod_crosswalk_dup", replace
file /Users/zsong98/Dropbox (Chicago Booth)/Bank Foot Traffic/data/source
    data/advan_sod_crosswalk_dup.dta saved

.         * within each duplicated match from uninumbr to id_store, keep only 
> the exact matched ones
.         bysort uninumbr (exact): keep if _n == 1
(194 observations deleted)

.         * note that there are still a few duplicates due to duplicated unibr
> anch 
.         duplicates tag id_store, gen(dup)

Duplicates in terms of id_store

.         tab dup  

        dup |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |     32,532       99.40       99.40
          1 |        188        0.57       99.98
          2 |          3        0.01       99.99
          3 |          4        0.01      100.00
------------+-----------------------------------
      Total |     32,727      100.00

.         * but looking over the duplicates shows that id_store is correctly m
> atched
.         * to each branch --
.         
. save "$datadir/advan_sod_crosswalk", replace
file /Users/zsong98/Dropbox (Chicago Booth)/Bank Foot Traffic/data/source
    data/advan_sod_crosswalk.dta saved

. 
. /**************
>         Histograms
>         ***************/
.         
. *** matching rates of banks in the Advan sample already
.         use "$datadir/advan_sod_crosswalk", clear

.         duplicates drop id_store, force

Duplicates in terms of id_store

(99 observations deleted)

.         merge 1:1 id_store using "$datadir/advan/t2/stores.dta"

    Result                      Number of obs
    -----------------------------------------
    Not matched                        16,020
        from master                         0  (_merge==1)
        from using                     16,020  (_merge==2)

    Matched                            32,628  (_merge==3)
    -----------------------------------------

.         replace bank_name = strlower(bank_name)
(16,020 real changes made)

.         egen matched = rowmax(exact fuzzy)
(16,020 missing values generated)

.         bysort bank_name: egen match_total = sum(matched)

.         bysort bank_name: gen match_rate = match_total / _N

.         * keep only those with matched total > 10 for plot
.         * keep if match_total > 10
.         * plot
.         graph hbar match_rate, over(bank_name, sort(1) descending label(labs
> ize(*0.3))) ytitle("Match Rate of Banks from Advan Sample") graphregion(colo
> r(white))

.         graph export "$figdir/advan_match_rate.pdf", replace
file /Users/zsong98/Dropbox (Chicago Booth)/Bank Foot
    Traffic/output/figures/zs/advan_match_rate.pdf saved as PDF format

.         graph hbar match_total, over(bank_name, sort(1) descending label(lab
> size(*0.3))) ytitle("Total Matched Branches from Advan Sample") graphregion(
> color(white))

.         graph export "$figdir/advan_match_total.pdf", replace
file /Users/zsong98/Dropbox (Chicago Booth)/Bank Foot
    Traffic/output/figures/zs/advan_match_total.pdf saved as PDF format

.         
. *** matching rates of banks from the SOD data
.         use "$datadir/advan_sod_crosswalk", clear

.         merge 1:1 uninumbr using "$datadir/SOD/sod_branch_location"

    Result                      Number of obs
    -----------------------------------------
    Not matched                        67,161
        from master                         0  (_merge==1)
        from using                     67,161  (_merge==2)

    Matched                            32,727  (_merge==3)
    -----------------------------------------

.         * standardize the newly merged full name of banks
.         replace namefull = strlower(namefull)
(67,157 real changes made)

.         replace namefull = subinstr(namefull, ", national association", "", 
> .)  
(11,752 real changes made)

.         egen matched = rowmax(exact fuzzy)
(67,161 missing values generated)

.         bysort namefull: egen match_total = sum(matched)

.         bysort namefull: gen match_rate = match_total / _N

.         * keep only those that have at least positive match rates 
.         drop if match_rate == 0
(42,585 observations deleted)

.         * keep only those with matched total > 15 for plot
.         keep if match_total > 15
(10,952 observations deleted)

.         * plot
.         graph hbar match_rate, over(namefull, sort(1) descending label(labsi
> ze(*0.30))) ytitle("Match Rate of Banks from SOD (only those with more than 
> 15 matches)") graphregion(color(white))

.         graph export "$figdir/sod_match_rate.pdf", replace
file /Users/zsong98/Dropbox (Chicago Booth)/Bank Foot
    Traffic/output/figures/zs/sod_match_rate.pdf saved as PDF format

.         graph hbar match_total, over(namefull, sort(1) descending label(labs
> ize(*0.30))) ytitle("Total Matched Branches from SOD (only those with more t
> han 15 matches)") graphregion(color(white))

.         graph export "$figdir/sod_match_total.pdf", replace
file /Users/zsong98/Dropbox (Chicago Booth)/Bank Foot
    Traffic/output/figures/zs/sod_match_total.pdf saved as PDF format

.         
. *** get unmatched sample for inspection 
.         use "$datadir/advan_sod_crosswalk_dup", clear

.         duplicates drop id_store, force

Duplicates in terms of id_store

(101 observations deleted)

.         merge 1:1 id_store using "$datadir/advan/t2/stores.dta"

    Result                      Number of obs
    -----------------------------------------
    Not matched                        15,828
        from master                         0  (_merge==1)
        from using                     15,828  (_merge==2)

    Matched                            32,820  (_merge==3)
    -----------------------------------------

.         keep if _merge == 2
(32,820 observations deleted)

.         drop _merge 

.         keep id_store address bank_name store_* city state ticker-country_co
> de dba

.         save "$datadir/unmatched_advan_branches.dta", replace
file /Users/zsong98/Dropbox (Chicago Booth)/Bank Foot Traffic/data/source
    data/unmatched_advan_branches.dta saved

.         
. /**************
>         Try to match unmatched sample (matching on city first)
>         ***************/
.         use "$datadir/unmatched_advan_branches.dta", clear

. 
. *** 1. joinby city (to generate all possible pairings within a zip code)
.         rename city citybr

.         keep id_store store_lat store_lon address citybr state zip bank_name
>  dba

.         joinby citybr using "$datadir/SOD/sod_branch_location"

.         
. *** order and sort variables for better view
.         gsort citybr id_store

.         order citybr id_store uninumbr bank_name namehcr store_lat store_lon
>  sims_latitude sims_longitude address addresbr zip zipbr state stalpbr

.         
.         * drop those that are not in the same cities (wrongly recorded zip c
> odes for PR)
.         * and longitude, latitude really far apart
.         gen lat_diff = abs(store_lat-sims_latitude) 

.         gen long_diff = abs(store_lon-sims_longitude)

.         drop if (state != stalpbr) | lat_diff > 0.5 | long_diff > 0.5
(312,917 observations deleted)

.         
. *** exact matches of address
.         * clean up the address abbreviations
.         * gen rid of dots in address
.         
.         foreach x in address addresbr {
  2.                 replace `x' = subinstr(`x', ".", "", .)
  3.                 replace `x' = subinstr(`x', " + ", " ", .)
  4.                 replace `x' = subinstr(`x', "Avenue", "Av", 1)
  5.                 replace `x' = subinstr(`x', "Ave", "Av", 1)
  6.                 replace `x' = subinstr(`x', "Road", "Rd", 1) 
  7.                 replace `x' = subinstr(`x', "Drive", "Dr", 1)
  8.                 replace `x' = subinstr(`x', "Place", "Pl", 1)
  9.                 replace `x' = subinstr(`x', "Boulevard", "Blvd", 1)
 10.                 replace `x' = subinstr(`x', "Route", "Rt", 1)
 11.                 replace `x' = subinstr(`x', "Highway", "Hwy", 1)
 12.                 replace `x' = subinstr(`x', "Street", "St", 1)
 13.                 replace `x' = subinstr(`x', "Suite", "Ste", 1)
 14.                 replace `x' = subinstr(`x', "Court", "CT", 1)
 15.                 replace `x' = subinstr(`x', "Circle", "CIR", 1)
 16.                 replace `x' = subinstr(`x', "Plaza", "Plz", 1)
 17.                 replace `x' = subinstr(`x', "Lane", "Ln", 1)
 18.                 replace `x' = subinstr(`x', "Parkway", "Pkwy", 1)
 19.                 replace `x' = subinstr(`x', "Floor", "Fl", 1)
 20.                 replace `x' = subinstr(`x', "Turnpike", "Tpke", 1)
 21.                 replace `x' = subinstr(`x', "Trail", "Tr", 1)
 22.                 replace `x' = subinstr(`x', "Square", "Sq", 1)
 23.                 * replace the North, South, West, East (direction ones
.                 replace `x' = subinstr(`x', " N ", " North ", 1)
 24.                 replace `x' = subinstr(`x', " S ", " South ", 1)
 25.                 replace `x' = subinstr(`x', " W ", " West ", 1)
 26.                 replace `x' = subinstr(`x', " E ", " East ", 1)
 27.                 replace `x' = subinstr(`x', " N", " North", 1) if substr(
> `x', -2, 2) == " N"
 28.                 replace `x' = subinstr(`x', " S", " South", 1) if substr(
> `x', -2, 2) == " S"
 29.                 replace `x' = subinstr(`x', " W", " West", 1) if substr(`
> x', -2, 2) == " W"
 30.                 replace `x' = subinstr(`x', " E", " East", 1) if substr(`
> x', -2, 2) == " E"
 31.                 * replace numbers (first-tenth)
.                 replace `x' = subinstr(`x', "Fisrt", "1st", 1)
 32.                 replace `x' = subinstr(`x', "Second", "2nd", 1)
 33.                 replace `x' = subinstr(`x', "Third", "3rd", 1)
 34.                 replace `x' = subinstr(`x', "Fourth", "4th", 1) 
 35.                 replace `x' = subinstr(`x', "Fifth", "5th", 1)
 36.                 replace `x' = subinstr(`x', "Sixth", "6th", 1)  
 37.                 replace `x' = subinstr(`x', "Seventh", "7th", 1)
 38.                 replace `x' = subinstr(`x', "Eighth", "8th", 1) 
 39.                 replace `x' = subinstr(`x', "Ninth", "9th", 1)  
 40.                 replace `x' = subinstr(`x', "Tenth", "10th", 1)
 41.                 replace `x' = subinstr(`x', "One", "1", 1)
 42.                 replace `x' = subinstr(`x', "Two", "2", 1)
 43.                 replace `x' = subinstr(`x', "Three", "3", 1)    
 44.                 replace `x' = subinstr(`x', "Four", "4", 1)     
 45.                 replace `x' = subinstr(`x', "Five", "5", 1)     
 46.                 replace `x' = subinstr(`x', "Six", "6", 1)      
 47.                 replace `x' = subinstr(`x', "Seven", "7", 1)    
 48.                 replace `x' = subinstr(`x', "Eight", "8", 1)    
 49.                 replace `x' = subinstr(`x', "Nine", "9", 1)     
 50.                 replace `x' = subinstr(`x', "Ten", "10", 1)     
 51.         }
(42,272 real changes made)
(0 real changes made)
(100,987 real changes made)
(149,043 real changes made)
(70,463 real changes made)
(23,163 real changes made)
(4,234 real changes made)
(30,410 real changes made)
(5,106 real changes made)
(14,059 real changes made)
(115,172 real changes made)
(31,806 real changes made)
(3,310 real changes made)
(3,395 real changes made)
(9,165 real changes made)
(6,209 real changes made)
(12,173 real changes made)
(12,652 real changes made)
(594 real changes made)
(2,683 real changes made)
(3,953 real changes made)
(70,851 real changes made)
(62,204 real changes made)
(67,354 real changes made)
(51,482 real changes made)
(9,713 real changes made)
(7,596 real changes made)
(4,382 real changes made)
(6,813 real changes made)
(0 real changes made)
(1,314 real changes made)
(2,778 real changes made)
(1,513 real changes made)
(2,478 real changes made)
(1,501 real changes made)
(368 real changes made)
(1,349 real changes made)
(44 real changes made)
(47 real changes made)
(4,091 real changes made)
(697 real changes made)
(69 real changes made)
(77 real changes made)
(137 real changes made)
(156 real changes made)
(503 real changes made)
(260 real changes made)
(65 real changes made)
(243 real changes made)
(105,509 real changes made)
(1 real change made)
(218,488 real changes made)
(48,182 real changes made)
(164,119 real changes made)
(54,111 real changes made)
(4,209 real changes made)
(76,339 real changes made)
(3,129 real changes made)
(26,221 real changes made)
(245,459 real changes made)
(85,197 real changes made)
(3,106 real changes made)
(3,170 real changes made)
(6,789 real changes made)
(13,328 real changes made)
(21,489 real changes made)
(6,787 real changes made)
(940 real changes made)
(3,867 real changes made)
(4,256 real changes made)
(29,227 real changes made)
(23,404 real changes made)
(30,179 real changes made)
(21,268 real changes made)
(2,632 real changes made)
(2,610 real changes made)
(2,371 real changes made)
(1,696 real changes made)
(0 real changes made)
(3,473 real changes made)
(7,183 real changes made)
(2,179 real changes made)
(7,917 real changes made)
(982 real changes made)
(2,072 real changes made)
(974 real changes made)
(745 real changes made)
(371 real changes made)
(4,265 real changes made)
(1,159 real changes made)
(160 real changes made)
(166 real changes made)
(352 real changes made)
(684 real changes made)
(187 real changes made)
(234 real changes made)
(158 real changes made)
(443 real changes made)

. 
.         * change all strings to lowercase
.         foreach str in address addresbr bank_name dba namehcr namefull {
  2.                 replace `str' = strlower(`str')
  3.         }
(1,152,736 real changes made)
(1,152,735 real changes made)
(1,152,767 real changes made)
(1,152,767 real changes made)
(1,095,233 real changes made)
(1,152,745 real changes made)

.         
.         gen exact = 1 if address == addresbr
(1,151,610 missing values generated)

.                 
.         * keep those that have been exactly matched in a tempfile 
.         preserve

.                 keep if exact == 1
(1,151,610 observations deleted)

.                 *** note that the exact matches have duplicates (one id_stor
> e matched to multiple branches)
.                 replace namefull = subinstr(namefull, ", national associatio
> n", "", .)  
(655 real changes made)

.                 ustrdist bank_name namehcr, gen(banknamedist1)

.                 ustrdist bank_name namefull, gen(banknamedist2)

.                 ustrdist dba namehcr, gen(banknamedist3)

.                 ustrdist dba namefull, gen(banknamedist4)

.                 egen bankname_dist = rowmin(banknamedist1 banknamedist2 bank
> namedist3 banknamedist4)

.                 drop banknamedist*

.                 * within exact exactly matched address, keep only the one br
> anch that has the closest name to the bank_name in case of duplicates (in ca
> se where there is no duplicates, the name different is ok as there are merge
> rs and acquisitions and change of local branch name sometimes)
.                 bysort id_store (bankname_dist): egen bankname_dist_min = mi
> n(bankname_dist)

.                 keep if bankname_dist_min == bankname_dist
(17 observations deleted)

.                 * do the same for each unique uninumbr as well
.                 drop bankname_dist_min

.                 bysort uninumbr (bankname_dist): egen bankname_dist_min = mi
> n(bankname_dist)

.                 keep if bankname_dist_min == bankname_dist
(5 observations deleted)

.                 tempfile exact_city

.                 save `exact_city', replace
(file C:\Users\zsong98\AppData\Local\Temp\ST_462c_000005.tmp not found)
file C:\Users\zsong98\AppData\Local\Temp\ST_462c_000005.tmp saved as .dta
    format

.         restore

.         * and drop the id_stores that have been exactly matched
.         bysort id_store: egen exact_matched = max(exact) 
(1,088,868 missing values generated)

.         sum lat_diff long_diff if exact == 1 // get a sense of how close (la
> t-long) the exact matches are 

    Variable |        Obs        Mean    Std. dev.       Min        Max
-------------+---------------------------------------------------------
    lat_diff |      1,157    .0023671    .0085167          0   .1151123
   long_diff |      1,157    .0033229    .0139192          0   .3391037

.         drop if exact_matched == 1      
(63,899 observations deleted)

.         
. *** fuzzy matches based on distances
.         ustrdist address addresbr, gen(addresdist)

.         gsort citybr id_store addresdist

.         order addresdist address addresbr bank_name namehcr namefull *_diff

.         
.         * keep only Levenstein distances smaller than 10 ones 
.         drop if addresdist > 10 
(952,001 observations deleted)

.         
.         // note that for the exact matches, the lat-long differences are aro
> und 0.0022 and 0.0031
. 
.         * 1. get string distances between bank_name (advan) and namehcr/name
> full (SOD)
.                 replace namefull = subinstr(namefull, ", national associatio
> n", "", .)  
(66,188 real changes made)

.                 ustrdist bank_name namehcr, gen(banknamedist1)

.                 ustrdist bank_name namefull, gen(banknamedist2)

.                 ustrdist dba namehcr, gen(banknamedist3)

.                 ustrdist dba namefull, gen(banknamedist4)

.                 egen bankname_dist = rowmin(banknamedist1 banknamedist2 bank
> namedist3 banknamedist4)

.                 drop banknamedist*

.                 * manually check for a threshold that shows that bank names 
> are the same
.                 gsort citybr id_store bankname_dist

.                 * also keep only the closest bank names for each unique stor
> e 
.                 bysort id_store (bankname_dist): keep if _n == 1
(125,105 observations deleted)

.                 drop if bankname_dist > 5               
(5,988 observations deleted)

.         
.         * 2. now check the lat-long coordinates and addresses to see if we h
> ave good matches    
.                 order id_store uninumbr zip zipbr *_diff

.                 
.                 drop if addresdist > 3
(4,467 observations deleted)

.                 drop if lat_diff > 0.002 | long_diff > 0.002 // here we are 
> really conservative as there are also pretty good matchings if we take lat/l
> ong_diff to be around 0.002. 
(844 observations deleted)

.                 gen fuzzy = 1 

.                 
. *** merge exact and fuzzy match results together
.         append using "`exact_city'"

.         
.         * order and keep variables 
.         keep bank_name name* address addresbr zipbr id_store uninumbr store_
> lat store_lon sims_* citybr state exact fuzzy 

.         replace exact = 0 if exact >=.
(463 real changes made)

.         replace fuzzy = 0 if fuzzy >=.
(1,135 real changes made)

.         
.         order id_store uninumbr 

.                 
.         save "$datadir/advan_sod_crosswalk_city", replace
file /Users/zsong98/Dropbox (Chicago Booth)/Bank Foot Traffic/data/source
    data/advan_sod_crosswalk_city.dta saved

.         * within each duplicated match from uninumbr to id_store, keep only 
> the exact matched ones
.         bysort uninumbr (exact): keep if _n == 1
(9 observations deleted)

.         * note that there are still a few duplicates due to duplicated unibr
> anch 
.         duplicates tag id_store, gen(dup)

Duplicates in terms of id_store

.         tab dup  

        dup |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      1,583       99.62       99.62
          1 |          6        0.38      100.00
------------+-----------------------------------
      Total |      1,589      100.00

.         * but looking over the duplicates shows that id_store is correctly m
> atched
.         * to each branch --
.         
.         append using "$datadir/advan_sod_crosswalk"

.         save "$datadir/advan_sod_crosswalk_full", replace
file /Users/zsong98/Dropbox (Chicago Booth)/Bank Foot Traffic/data/source
    data/advan_sod_crosswalk_full.dta saved

.         
. *** get unmatched sample after having matched on zip and city for merge
.         use "$datadir/advan_sod_crosswalk_full", clear

.         duplicates drop id_store, force

Duplicates in terms of id_store

(102 observations deleted)

.         merge 1:1 id_store using "$datadir/advan/t2/stores.dta"

    Result                      Number of obs
    -----------------------------------------
    Not matched                        14,434
        from master                         0  (_merge==1)
        from using                     14,434  (_merge==2)

    Matched                            34,214  (_merge==3)
    -----------------------------------------

.         keep if _merge == 2
(34,214 observations deleted)

.         drop _merge 

.         keep id_store address bank_name store_* city state ticker-country_co
> de dba

.         save "$datadir/unmatched_advan_branches.dta", replace
file /Users/zsong98/Dropbox (Chicago Booth)/Bank Foot Traffic/data/source
    data/unmatched_advan_branches.dta saved

. ****************************************************************************
> ****
. capture log close
