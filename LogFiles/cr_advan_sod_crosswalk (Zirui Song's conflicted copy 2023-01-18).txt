---------------------------------------------------------------------------------------
      name:  <unnamed>
       log:  C:/Users/zsong98/Dropbox (Chicago Booth)/Bank Foot Traffic/code/LogFiles/c
> r_advan_sod_crosswalk.txt
  log type:  text
 opened on:  18 Jan 2023, 10:52:44

. 
. /**************
>         Clean Data
>         ***************/
.         
.         use "$datadir/SOD/sodupdate2021.dta", clear

. * first drop all years prior to 2015 as Advan data only from 2015-2022
.         gsort year

.         drop if year < 2015
(1,897,012 observations deleted)

.         
. * check uninumbr (unique location for each branch (regardless of M&As)
.         gsort uninumbr

.         
. * drop duplicates and also keep only variables useful for matching
.         keep rssdid uninumbr-zipbr city2br sims_latitude sims_longitude namehcr 

.         * make sure lat and long are not missing
.         drop if sims_latitude == . | sims_longitude == .s
(1,593 observations deleted)

.         gduplicates drop 

Duplicates in terms of all variables

(358,575 observations deleted)

.         * keep the first ones
.         bysort uninumbr: keep if _n == 1
(156,170 observations deleted)

.         save "$datadir/SOD/sod_branch_location", replace
file /Users/zsong98/Dropbox (Chicago Booth)/Bank Foot Traffic/data/source
    data/SOD/sod_branch_location.dta saved

. 
.         * the chunk below only applies to mapping when we haven't received store info
> rmation 
.         * on bank names from Advan ---
.         /*
> *** clean bank ticker mapping
>         import excel "$datadir/SOD/Bank_Ticker_Mapping.xlsx", clear
>         keep B C 
>         rename (B C) (bank_name ticker_mother_company)
>         tempfile ticker_map
>         save `ticker_map'
>         
>         import delimited "$repodir/advan/t2/stores_vXV.csv", clear
> * keep only US ones 
>         keep if country_code == "US"
>         
>         * split the strings s.t. we have only the mother company for bank tickers
>         split ticker, parse("-") limit(1) gen(ticker_mother_company)
>         rename ticker_mother_company1 ticker_mother_company
>          
>         merge m:1 ticker_mother_company using "`ticker_map'"
>                 * manually check and put in bank names for those that are not matched
>  
>                 tab ticker if _merge == 1
>                 tab ticker_mother_company if _merge == 1
>                 replace bank_name = "BB&T Corporation" if ticker == "BBT"
>                 replace bank_name = "Beacon Bancorp" if ticker == "BEACON-A-BCSB"
>                 replace bank_name = "BNP Paribas SA" if ticker == "BNPQF-BW"
>                 replace bank_name = "Carolina Financial Corporation" if ticker == "CA
> RO-CRESCOM"
>                 replace bank_name = "Cornerstone Bancorp" if ticker == "CNBP"
>                 replace bank_name = "Fidelity Bank" if ticker == "FIDEL-A" 
>                 replace bank_name = "F&M Bank Corp" if ticker_mother_company == "FMBM
> "
>                 replace bank_name = "Keycorp" if ticker == "FNFG"
>                 replace bank_name = "Gorham Savings Bank" if ticker == "GORHAM-A"
>                 replace bank_name = "HSBC Holdings plc" if ticker == "HBCYF"
>                 replace bank_name = "John Marshall Bancorp" if ticker == "JMSB"
>                 replace bank_name = "Mascoma Bank" if ticker == "MASCOMA-A"
>                 replace bank_name = "Ozark Bank" if ticker == "OZRK"
>                 replace bank_name = "Banco Santander SA" if ticker == "SAN"
>                 replace bank_name = "Suntruct Banks, Inc." if ticker == "STI"
>                 replace bank_name = "Toronto-Dominion Bank" if ticker == "TD"
>                 replace bank_name = "TSB Bank" if ticker == "TSB-A"
> 
>         drop _merge 
>         drop if bank_name == ""
>                 */      
.                 
.         * using store information sent by Advan to obtain bank names (more accurate)
.         import delimited "$datadir/advan/t2/stores_info.csv", clear
(encoding automatically selected: ISO-8859-1)
(5 vars, 48,953 obs)

.                 tempfile store_name

.                 save `store_name'
file C:\Users\zsong98\AppData\Local\Temp\ST_2184_000001.tmp saved as .dta format

.         import delimited "$datadir/advan/t2/stores_vXV.csv", clear
(encoding automatically selected: ISO-8859-1)
(16 vars, 55,832 obs)

.         merge 1:1 id_store using `store_name', keepusing(company_name dba)

    Result                      Number of obs
    -----------------------------------------
    Not matched                         7,489
        from master                     7,184  (_merge==1)
        from using                        305  (_merge==2)

    Matched                            48,648  (_merge==3)
    -----------------------------------------

.         
. /*      unmatched from master mainly due to foreign banks (only 3 are not)
>     Result                      Number of obs
>     -----------------------------------------
>     Not matched                         7,489
>         from master                     7,184  (_merge==1)
>         from using                        305  (_merge==2)
> 
>     Matched                            48,648  (_merge==3)
>     -----------------------------------------
> */
.         keep if _merge == 3
(7,489 observations deleted)

.         drop _merge

.         rename company_name bank_name

.         
.         * save as intermediate to investigate matching rates later on
.         save "$datadir/advan/t2/stores.dta", replace
file /Users/zsong98/Dropbox (Chicago Booth)/Bank Foot Traffic/data/source
    data/advan/t2/stores.dta saved

. /**************
>         Matching Step
>         ***************/
. 
. *** 1. joinby zip code (to generate all possible pairings within a zip code)
.         * drop the strings with .0 at the end or zipcodes with form xxxxx-xxxx
.         replace zip = substr(zip, 1, strlen(zip)-2) if substr(zip, -2, 2) == ".0"
(588 real changes made)

.         replace zip = substr(zip, 1, strlen(zip)-5) if substr(zip, -5, 1) == "-"
(2,883 real changes made)

.         rename zip zipbr

.         destring zipbr, replace
zipbr: all characters numeric; replaced as long

.         * keep only useful variables
.         keep id_store store_lat store_lon address city state zipbr bank_name dba

.         joinby zipbr using "$datadir/SOD/sod_branch_location"

.         
. *** order and sort variables for better view
.         gsort zipbr id_store

.         order zipbr id_store uninumbr bank_name namehcr store_lat store_lon sims_lati
> tude sims_longitude address addresbr city citybr state stalpbr

.         
.         * drop those that are not in the same cities (wrongly recorded zip codes for 
> PR)
.         * and longitude, latitude really far apart
.         gen lat_diff = abs(store_lat-sims_latitude) 

.         gen long_diff = abs(store_lon-sims_longitude)
(4 missing values generated)

.         drop if (state != stalpbr) | lat_diff > 0.5 | long_diff > 0.5
(1,260 observations deleted)

.         
. *** exact matches of address
.         * clean up the address abbreviations
.         * gen rid of dots in address
.         
.         foreach x in address addresbr {
  2.                 replace `x' = subinstr(`x', ".", "", .)
  3.                 replace `x' = subinstr(`x', " + ", " ", .)
  4.                 replace `x' = subinstr(`x', "Avenue", "Av", 1)
  5.                 replace `x' = subinstr(`x', "Ave", "Av", 1)
  6.                 replace `x' = subinstr(`x', "Road", "Rd", 1) 
  7.                 replace `x' = subinstr(`x', "Drive", "Dr", 1)
  8.                 replace `x' = subinstr(`x', "Place", "Pl", 1)
  9.                 replace `x' = subinstr(`x', "Boulevard", "Blvd", 1)
 10.                 replace `x' = subinstr(`x', "Route", "Rt", 1)
 11.                 replace `x' = subinstr(`x', "Highway", "Hwy", 1)
 12.                 replace `x' = subinstr(`x', "Street", "St", 1)
 13.                 replace `x' = subinstr(`x', "Suite", "Ste", 1)
 14.                 replace `x' = subinstr(`x', "Court", "CT", 1)
 15.                 replace `x' = subinstr(`x', "Circle", "CIR", 1)
 16.                 replace `x' = subinstr(`x', "Plaza", "Plz", 1)
 17.                 replace `x' = subinstr(`x', "Lane", "Ln", 1)
 18.                 replace `x' = subinstr(`x', "Parkway", "Pkwy", 1)
 19.                 replace `x' = subinstr(`x', "Floor", "Fl", 1)
 20.                 replace `x' = subinstr(`x', "Turnpike", "Tpke", 1)
 21.                 replace `x' = subinstr(`x', "Trail", "Tr", 1)
 22.                 * replace the North, South, West, East (direction ones
.                 replace `x' = subinstr(`x', " N ", " North ", 1)
 23.                 replace `x' = subinstr(`x', " S ", " South ", 1)
 24.                 replace `x' = subinstr(`x', " W ", " West ", 1)
 25.                 replace `x' = subinstr(`x', " E ", " East ", 1)
 26.                 replace `x' = subinstr(`x', " N", " North", 1) if substr(`x', -2, 
> 2) == " N"
 27.                 replace `x' = subinstr(`x', " S", " South", 1) if substr(`x', -2, 
> 2) == " S"
 28.                 replace `x' = subinstr(`x', " W", " West", 1) if substr(`x', -2, 2
> ) == " W"
 29.                 replace `x' = subinstr(`x', " E", " East", 1) if substr(`x', -2, 2
> ) == " E"
 30.                 * replace numbers (first-tenth)
.                 replace `x' = subinstr(`x', "Fisrt", "1st", 1)
 31.                 replace `x' = subinstr(`x', "Second", "2nd", 1)
 32.                 replace `x' = subinstr(`x', "Third", "3rd", 1)
 33.                 replace `x' = subinstr(`x', "Fourth", "4th", 1) 
 34.                 replace `x' = subinstr(`x', "Fifth", "5th", 1)
 35.                 replace `x' = subinstr(`x', "Sixth", "6th", 1)  
 36.                 replace `x' = subinstr(`x', "Seventh", "7th", 1)
 37.                 replace `x' = subinstr(`x', "Eighth", "8th", 1) 
 38.                 replace `x' = subinstr(`x', "Ninth", "9th", 1)  
 39.                 replace `x' = subinstr(`x', "Tenth", "10th", 1)
 40.                 replace `x' = subinstr(`x', "One", "1", 1)
 41.                 replace `x' = subinstr(`x', "Two", "2", 1)
 42.                 replace `x' = subinstr(`x', "Three", "3", 1)    
 43.                 replace `x' = subinstr(`x', "Four", "4", 1)     
 44.                 replace `x' = subinstr(`x', "Five", "5", 1)     
 45.                 replace `x' = subinstr(`x', "Six", "6", 1)      
 46.                 replace `x' = subinstr(`x', "Seven", "7", 1)    
 47.                 replace `x' = subinstr(`x', "Eight", "8", 1)    
 48.                 replace `x' = subinstr(`x', "Nine", "9", 1)     
 49.                 replace `x' = subinstr(`x', "Ten", "10", 1)     
 50.         }
(24,765 real changes made)
(0 real changes made)
(38,741 real changes made)
(63,631 real changes made)
(48,997 real changes made)
(13,381 real changes made)
(1,471 real changes made)
(16,993 real changes made)
(6,567 real changes made)
(15,026 real changes made)
(57,634 real changes made)
(7,285 real changes made)
(1,824 real changes made)
(1,482 real changes made)
(3,016 real changes made)
(2,372 real changes made)
(5,173 real changes made)
(1,901 real changes made)
(1,114 real changes made)
(2,324 real changes made)
(31,780 real changes made)
(31,077 real changes made)
(33,196 real changes made)
(29,663 real changes made)
(3,981 real changes made)
(4,182 real changes made)
(2,734 real changes made)
(3,079 real changes made)
(0 real changes made)
(937 real changes made)
(998 real changes made)
(427 real changes made)
(845 real changes made)
(305 real changes made)
(256 real changes made)
(175 real changes made)
(170 real changes made)
(92 real changes made)
(781 real changes made)
(293 real changes made)
(57 real changes made)
(70 real changes made)
(114 real changes made)
(310 real changes made)
(151 real changes made)
(45 real changes made)
(65 real changes made)
(267 real changes made)
(39,869 real changes made)
(7 real changes made)
(85,469 real changes made)
(15,867 real changes made)
(104,116 real changes made)
(31,180 real changes made)
(2,583 real changes made)
(39,114 real changes made)
(6,765 real changes made)
(22,619 real changes made)
(123,321 real changes made)
(31,417 real changes made)
(2,243 real changes made)
(2,252 real changes made)
(3,664 real changes made)
(5,153 real changes made)
(12,948 real changes made)
(1,718 real changes made)
(2,092 real changes made)
(2,856 real changes made)
(11,365 real changes made)
(9,753 real changes made)
(10,845 real changes made)
(9,892 real changes made)
(1,271 real changes made)
(1,218 real changes made)
(1,022 real changes made)
(987 real changes made)
(0 real changes made)
(1,688 real changes made)
(2,869 real changes made)
(1,145 real changes made)
(1,990 real changes made)
(580 real changes made)
(592 real changes made)
(385 real changes made)
(365 real changes made)
(254 real changes made)
(2,052 real changes made)
(387 real changes made)
(156 real changes made)
(154 real changes made)
(148 real changes made)
(423 real changes made)
(208 real changes made)
(99 real changes made)
(86 real changes made)
(294 real changes made)

. 
.         * change all strings to lowercase
.         foreach str in address addresbr bank_name dba namehcr namefull {
  2.                 replace `str' = strlower(`str')
  3.         }
(570,337 real changes made)
(570,344 real changes made)
(570,365 real changes made)
(570,365 real changes made)
(535,204 real changes made)
(570,328 real changes made)

.         
.         gen exact = 1 if address == addresbr
(539,168 missing values generated)

.                 
.         * keep those that have been exactly matched in a tempfile 
.         preserve

.                 keep if exact == 1
(539,168 observations deleted)

.                 *** note that the exact matches have duplicates (one id_store matched
>  to multiple branches)
.                 replace namefull = subinstr(namefull, ", national association", "", .
> )  
(18,239 real changes made)

.                 ustrdist bank_name namehcr, gen(banknamedist1)

.                 ustrdist bank_name namefull, gen(banknamedist2)

.                 ustrdist dba namehcr, gen(banknamedist3)

.                 ustrdist dba namefull, gen(banknamedist4)

.                 egen bankname_dist = rowmin(banknamedist1 banknamedist2 banknamedist3
>  banknamedist4)

.                 drop banknamedist*

.                 * within exact exactly matched address, keep only the one branch that
>  has the closest name to the bank_name in case of duplicates (in case where there is 
> no duplicates, the name different is ok as there are mergers and acquisitions and cha
> nge of local branch name sometimes)
.                 bysort id_store (bankname_dist): egen bankname_dist_min = min(banknam
> e_dist)

.                 keep if bankname_dist_min == bankname_dist
(406 observations deleted)

.                 * do the same for each unique uninumbr as well
.                 drop bankname_dist_min

.                 bysort uninumbr (bankname_dist): egen bankname_dist_min = min(banknam
> e_dist)

.                 keep if bankname_dist_min == bankname_dist
(627 observations deleted)

.                 tempfile exact

.                 save `exact', replace
(file C:\Users\zsong98\AppData\Local\Temp\ST_2184_000003.tmp not found)
file C:\Users\zsong98\AppData\Local\Temp\ST_2184_000003.tmp saved as .dta format

.         restore

.         * and drop the id_stores that have been exactly matched
.         bysort id_store: egen exact_matched = max(exact) 
(205,780 missing values generated)

.         sum lat_diff long_diff if exact == 1 // get a sense of how close (lat-long) t
> he exact matches are 

    Variable |        Obs        Mean    Std. dev.       Min        Max
-------------+---------------------------------------------------------
    lat_diff |     31,197     .001476    .0082573          0   .3920288
   long_diff |     31,197    .0017962     .009788          0   .4954987

.         drop if exact_matched == 1
(364,585 observations deleted)

.         
. *** fuzzy matches based on distances
.         ustrdist address addresbr, gen(addresdist)

.         gsort zipbr id_store addresdist

.         order addresdist address addresbr bank_name namehcr namefull *_diff

.         
.         * keep only Levenstein distances smaller than 10 ones 
.         drop if addresdist > 10 
(145,258 observations deleted)

.         
.         /* 1. within each zip-id_store combinations, first keep the ones with Levenst
> ein distances <= 2 
>         gen fuzzy_dist_1 = 1 if addresdist == 1
>         * save the above data 
>         preserve
>                 keep if fuzzy_dist_1 == 1
>                 tempfile fuzzy_dist_1
>                 save `fuzzy_dist_1', replace
>         restore
>         * and drop the id_stores that have been exactly matched
>         bysort id_store: egen fuzzy_dist_1_matched = max(fuzzy_dist_1) 
>         sum lat_diff long_diff if fuzzy_dist_1 == 1 // get a sense of how close the f
> uzzy dist 1 matches are 
>         drop if fuzzy_dist_1_matched == 1
>         */
.         // note that for the exact matches, the lat-long differences are around 0.001
> 5 
. 
.         * 1. get string distances between bank_name (advan) and namehcr/namefull (SOD
> )
.                 replace namefull = subinstr(namefull, ", national association", "", .
> )  
(25,229 real changes made)

.                 ustrdist bank_name namehcr, gen(banknamedist1)

.                 ustrdist bank_name namefull, gen(banknamedist2)

.                 ustrdist dba namehcr, gen(banknamedist3)

.                 ustrdist dba namefull, gen(banknamedist4)

.                 egen bankname_dist = rowmin(banknamedist1 banknamedist2 banknamedist3
>  banknamedist4)

.                 drop banknamedist*

.                 * manually check for a threshold that shows that bank names are the s
> ame
.                 gsort zipbr id_store bankname_dist

.                 * also keep only the closest bank names for each unique store 
.                 bysort id_store (bankname_dist): keep if _n == 1
(46,113 observations deleted)

.                 drop if bankname_dist > 5               
(6,615 observations deleted)

.         
.         * 2. now check the lat-long coordinates and addresses to see if we have good 
> matches    
.                 drop if addresdist > 5
(3,051 observations deleted)

.                 drop if lat_diff > 0.001 | long_diff > 0.001 // here we are really co
> nservative as there are also pretty good matchings if we take lat/long_diff to be aro
> und 0.002. 
(2,034 observations deleted)

.                 gen fuzzy = 1 

. 
. *** merge exact and fuzzy match results together
.         append using "`exact'"

.         
.         * order and keep variables (keep rssdid to find bank M&As)
.         keep rssdid bank_name name* address addresbr zipbr id_store uninumbr store_la
> t store_lon sims_* city state exact fuzzy 

.         replace exact = 0 if exact >=.
(2,709 real changes made)

.         replace fuzzy = 0 if fuzzy >=.
(30,164 real changes made)

.         
.         order id_store uninumbr 

.                 
.         save "$datadir/advan_sod_crosswalk_dup", replace
file /Users/zsong98/Dropbox (Chicago Booth)/Bank Foot Traffic/data/source
    data/advan_sod_crosswalk_dup.dta saved

.         * within each duplicated match from uninumbr to id_store, keep only the exact
>  matched ones
.         bysort uninumbr (exact): keep if _n == 1
(195 observations deleted)

.         * note that there are still a few duplicates due to duplicated unibranch 
.         duplicates tag id_store, gen(dup)

Duplicates in terms of id_store

.         tab dup  

        dup |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |     32,496       99.44       99.44
          1 |        176        0.54       99.98
          2 |          6        0.02      100.00
------------+-----------------------------------
      Total |     32,678      100.00

.         * but looking over the duplicates shows that id_store is correctly matched
.         * to each branch --
.         
. save "$datadir/advan_sod_crosswalk", replace
file /Users/zsong98/Dropbox (Chicago Booth)/Bank Foot Traffic/data/source
    data/advan_sod_crosswalk.dta saved

. 
. /**************
>         Histograms
>         ***************/
.         
. *** matching rates of banks in the Advan sample already
.         use "$datadir/advan_sod_crosswalk", clear

.         duplicates drop id_store, force

Duplicates in terms of id_store

(92 observations deleted)

.         merge 1:1 id_store using "$datadir/advan/t2/stores.dta"

    Result                      Number of obs
    -----------------------------------------
    Not matched                        16,062
        from master                         0  (_merge==1)
        from using                     16,062  (_merge==2)

    Matched                            32,586  (_merge==3)
    -----------------------------------------

.         replace bank_name = strlower(bank_name)
(16,062 real changes made)

.         egen matched = rowmax(exact fuzzy)
(16,062 missing values generated)

.         bysort bank_name: egen match_total = sum(matched)

.         bysort bank_name: gen match_rate = match_total / _N

.         * keep only those with matched total > 10 for plot
.         * keep if match_total > 10
.         * plot
.         graph hbar match_rate, over(bank_name, sort(1) descending label(labsize(*0.3)
> )) ytitle("Match Rate of Banks from Advan Sample") graphregion(color(white))

.         graph export "$figdir/advan_match_rate.pdf", replace
file /Users/zsong98/Dropbox (Chicago Booth)/Bank Foot
    Traffic/output/figures/zs/advan_match_rate.pdf saved as PDF format

.         graph hbar match_total, over(bank_name, sort(1) descending label(labsize(*0.3
> ))) ytitle("Total Matched Branches from Advan Sample") graphregion(color(white))

.         graph export "$figdir/advan_match_total.pdf", replace
file /Users/zsong98/Dropbox (Chicago Booth)/Bank Foot
    Traffic/output/figures/zs/advan_match_total.pdf saved as PDF format

.         
. *** matching rates of banks from the SOD data
.         use "$datadir/advan_sod_crosswalk", clear

.         merge 1:1 uninumbr using "$datadir/SOD/sod_branch_location"

    Result                      Number of obs
    -----------------------------------------
    Not matched                        67,210
        from master                         0  (_merge==1)
        from using                     67,210  (_merge==2)

    Matched                            32,678  (_merge==3)
    -----------------------------------------

.         * standardize the newly merged full name of banks
.         replace namefull = strlower(namefull)
(67,206 real changes made)

.         replace namefull = subinstr(namefull, ", national association", "", .)  
(11,806 real changes made)

.         egen matched = rowmax(exact fuzzy)
(67,210 missing values generated)

.         bysort namefull: egen match_total = sum(matched)

.         bysort namefull: gen match_rate = match_total / _N

.         * keep only those that have at least positive match rates 
.         drop if match_rate == 0
(42,515 observations deleted)

.         * keep only those with matched total > 15 for plot
.         keep if match_total > 15
(11,831 observations deleted)

.         * plot
.         graph hbar match_rate, over(namefull, sort(1) descending label(labsize(*0.30)
> )) ytitle("Match Rate of Banks from SOD (only those with more than 15 matches)") grap
> hregion(color(white))

.         graph export "$figdir/sod_match_rate.pdf", replace
file /Users/zsong98/Dropbox (Chicago Booth)/Bank Foot
    Traffic/output/figures/zs/sod_match_rate.pdf saved as PDF format

.         graph hbar match_total, over(namefull, sort(1) descending label(labsize(*0.30
> ))) ytitle("Total Matched Branches from SOD (only those with more than 15 matches)") 
> graphregion(color(white))

.         graph export "$figdir/sod_match_total.pdf", replace
file /Users/zsong98/Dropbox (Chicago Booth)/Bank Foot
    Traffic/output/figures/zs/sod_match_total.pdf saved as PDF format

.         
. *** get unmatched sample for inspection 
.         use "$datadir/advan_sod_crosswalk_dup", clear

.         duplicates drop id_store, force

Duplicates in terms of id_store

(93 observations deleted)

.         merge 1:1 id_store using "$datadir/advan/t2/stores.dta"

    Result                      Number of obs
    -----------------------------------------
    Not matched                        15,868
        from master                         0  (_merge==1)
        from using                     15,868  (_merge==2)

    Matched                            32,780  (_merge==3)
    -----------------------------------------

.         keep if _merge == 2
(32,780 observations deleted)

.         drop _merge 

.         keep id_store address bank_name store_* city state ticker-country_code dba

.         save "$datadir/unmatched_advan_branches.dta", replace
file /Users/zsong98/Dropbox (Chicago Booth)/Bank Foot Traffic/data/source
    data/unmatched_advan_branches.dta saved

.         
. /**************
>         Try to match unmatched sample (matching on city first)
>         ***************/
.         use "$datadir/unmatched_advan_branches.dta", clear

. 
. *** 1. joinby city (to generate all possible pairings within a zip code)
.         rename city citybr

.         keep id_store store_lat store_lon address citybr state zip bank_name dba

.         joinby citybr using "$datadir/SOD/sod_branch_location"

.         
. *** order and sort variables for better view
.         gsort citybr id_store

.         order citybr id_store uninumbr bank_name namehcr store_lat store_lon sims_lat
> itude sims_longitude address addresbr zip zipbr state stalpbr

.         
.         * drop those that are not in the same cities (wrongly recorded zip codes for 
> PR)
.         * and longitude, latitude really far apart
.         gen lat_diff = abs(store_lat-sims_latitude) 

.         gen long_diff = abs(store_lon-sims_longitude)
(6 missing values generated)

.         drop if (state != stalpbr) | lat_diff > 0.5 | long_diff > 0.5
(314,357 observations deleted)

.         
. *** exact matches of address
.         * clean up the address abbreviations
.         * gen rid of dots in address
.         
.         foreach x in address addresbr {
  2.                 replace `x' = subinstr(`x', ".", "", .)
  3.                 replace `x' = subinstr(`x', " + ", " ", .)
  4.                 replace `x' = subinstr(`x', "Avenue", "Av", 1)
  5.                 replace `x' = subinstr(`x', "Ave", "Av", 1)
  6.                 replace `x' = subinstr(`x', "Road", "Rd", 1) 
  7.                 replace `x' = subinstr(`x', "Drive", "Dr", 1)
  8.                 replace `x' = subinstr(`x', "Place", "Pl", 1)
  9.                 replace `x' = subinstr(`x', "Boulevard", "Blvd", 1)
 10.                 replace `x' = subinstr(`x', "Route", "Rt", 1)
 11.                 replace `x' = subinstr(`x', "Highway", "Hwy", 1)
 12.                 replace `x' = subinstr(`x', "Street", "St", 1)
 13.                 replace `x' = subinstr(`x', "Suite", "Ste", 1)
 14.                 replace `x' = subinstr(`x', "Court", "CT", 1)
 15.                 replace `x' = subinstr(`x', "Circle", "CIR", 1)
 16.                 replace `x' = subinstr(`x', "Plaza", "Plz", 1)
 17.                 replace `x' = subinstr(`x', "Lane", "Ln", 1)
 18.                 replace `x' = subinstr(`x', "Parkway", "Pkwy", 1)
 19.                 replace `x' = subinstr(`x', "Floor", "Fl", 1)
 20.                 replace `x' = subinstr(`x', "Turnpike", "Tpke", 1)
 21.                 replace `x' = subinstr(`x', "Trail", "Tr", 1)
 22.                 replace `x' = subinstr(`x', "Square", "Sq", 1)
 23.                 * replace the North, South, West, East (direction ones
.                 replace `x' = subinstr(`x', " N ", " North ", 1)
 24.                 replace `x' = subinstr(`x', " S ", " South ", 1)
 25.                 replace `x' = subinstr(`x', " W ", " West ", 1)
 26.                 replace `x' = subinstr(`x', " E ", " East ", 1)
 27.                 replace `x' = subinstr(`x', " N", " North", 1) if substr(`x', -2, 
> 2) == " N"
 28.                 replace `x' = subinstr(`x', " S", " South", 1) if substr(`x', -2, 
> 2) == " S"
 29.                 replace `x' = subinstr(`x', " W", " West", 1) if substr(`x', -2, 2
> ) == " W"
 30.                 replace `x' = subinstr(`x', " E", " East", 1) if substr(`x', -2, 2
> ) == " E"
 31.                 * replace numbers (first-tenth)
.                 replace `x' = subinstr(`x', "Fisrt", "1st", 1)
 32.                 replace `x' = subinstr(`x', "Second", "2nd", 1)
 33.                 replace `x' = subinstr(`x', "Third", "3rd", 1)
 34.                 replace `x' = subinstr(`x', "Fourth", "4th", 1) 
 35.                 replace `x' = subinstr(`x', "Fifth", "5th", 1)
 36.                 replace `x' = subinstr(`x', "Sixth", "6th", 1)  
 37.                 replace `x' = subinstr(`x', "Seventh", "7th", 1)
 38.                 replace `x' = subinstr(`x', "Eighth", "8th", 1) 
 39.                 replace `x' = subinstr(`x', "Ninth", "9th", 1)  
 40.                 replace `x' = subinstr(`x', "Tenth", "10th", 1)
 41.                 replace `x' = subinstr(`x', "One", "1", 1)
 42.                 replace `x' = subinstr(`x', "Two", "2", 1)
 43.                 replace `x' = subinstr(`x', "Three", "3", 1)    
 44.                 replace `x' = subinstr(`x', "Four", "4", 1)     
 45.                 replace `x' = subinstr(`x', "Five", "5", 1)     
 46.                 replace `x' = subinstr(`x', "Six", "6", 1)      
 47.                 replace `x' = subinstr(`x', "Seven", "7", 1)    
 48.                 replace `x' = subinstr(`x', "Eight", "8", 1)    
 49.                 replace `x' = subinstr(`x', "Nine", "9", 1)     
 50.                 replace `x' = subinstr(`x', "Ten", "10", 1)     
 51.         }
(41,194 real changes made)
(0 real changes made)
(100,760 real changes made)
(148,502 real changes made)
(69,328 real changes made)
(23,922 real changes made)
(3,982 real changes made)
(31,060 real changes made)
(5,203 real changes made)
(14,392 real changes made)
(115,557 real changes made)
(31,029 real changes made)
(3,613 real changes made)
(3,431 real changes made)
(8,507 real changes made)
(6,194 real changes made)
(12,183 real changes made)
(12,608 real changes made)
(712 real changes made)
(2,906 real changes made)
(4,042 real changes made)
(70,816 real changes made)
(61,775 real changes made)
(66,033 real changes made)
(49,115 real changes made)
(9,308 real changes made)
(7,544 real changes made)
(3,770 real changes made)
(6,601 real changes made)
(0 real changes made)
(1,319 real changes made)
(2,736 real changes made)
(1,313 real changes made)
(2,713 real changes made)
(1,486 real changes made)
(1,151 real changes made)
(964 real changes made)
(0 real changes made)
(47 real changes made)
(3,461 real changes made)
(695 real changes made)
(60 real changes made)
(77 real changes made)
(59 real changes made)
(155 real changes made)
(495 real changes made)
(258 real changes made)
(66 real changes made)
(243 real changes made)
(106,553 real changes made)
(1 real change made)
(217,397 real changes made)
(44,845 real changes made)
(165,091 real changes made)
(54,527 real changes made)
(4,249 real changes made)
(76,241 real changes made)
(3,206 real changes made)
(26,783 real changes made)
(248,480 real changes made)
(84,322 real changes made)
(2,938 real changes made)
(3,233 real changes made)
(6,754 real changes made)
(13,259 real changes made)
(21,467 real changes made)
(7,046 real changes made)
(913 real changes made)
(4,033 real changes made)
(4,314 real changes made)
(28,750 real changes made)
(22,061 real changes made)
(29,032 real changes made)
(20,383 real changes made)
(2,495 real changes made)
(2,335 real changes made)
(2,364 real changes made)
(1,653 real changes made)
(0 real changes made)
(3,428 real changes made)
(7,080 real changes made)
(2,290 real changes made)
(7,614 real changes made)
(1,079 real changes made)
(2,104 real changes made)
(1,103 real changes made)
(742 real changes made)
(370 real changes made)
(4,507 real changes made)
(1,277 real changes made)
(286 real changes made)
(159 real changes made)
(378 real changes made)
(674 real changes made)
(221 real changes made)
(224 real changes made)
(282 real changes made)
(437 real changes made)

. 
.         * change all strings to lowercase
.         foreach str in address addresbr bank_name dba namehcr namefull {
  2.                 replace `str' = strlower(`str')
  3.         }
(1,146,211 real changes made)
(1,146,208 real changes made)
(1,146,242 real changes made)
(1,146,242 real changes made)
(1,081,233 real changes made)
(1,146,219 real changes made)

.         
.         gen exact = 1 if address == addresbr
(1,145,088 missing values generated)

.                 
.         * keep those that have been exactly matched in a tempfile 
.         preserve

.                 keep if exact == 1
(1,145,088 observations deleted)

.                 *** note that the exact matches have duplicates (one id_store matched
>  to multiple branches)
.                 replace namefull = subinstr(namefull, ", national association", "", .
> )  
(707 real changes made)

.                 ustrdist bank_name namehcr, gen(banknamedist1)

.                 ustrdist bank_name namefull, gen(banknamedist2)

.                 ustrdist dba namehcr, gen(banknamedist3)

.                 ustrdist dba namefull, gen(banknamedist4)

.                 egen bankname_dist = rowmin(banknamedist1 banknamedist2 banknamedist3
>  banknamedist4)

.                 drop banknamedist*

.                 * within exact exactly matched address, keep only the one branch that
>  has the closest name to the bank_name in case of duplicates (in case where there is 
> no duplicates, the name different is ok as there are mergers and acquisitions and cha
> nge of local branch name sometimes)
.                 bysort id_store (bankname_dist): egen bankname_dist_min = min(banknam
> e_dist)

.                 keep if bankname_dist_min == bankname_dist
(14 observations deleted)

.                 * do the same for each unique uninumbr as well
.                 drop bankname_dist_min

.                 bysort uninumbr (bankname_dist): egen bankname_dist_min = min(banknam
> e_dist)

.                 keep if bankname_dist_min == bankname_dist
(4 observations deleted)

.                 tempfile exact_city

.                 save `exact_city', replace
(file C:\Users\zsong98\AppData\Local\Temp\ST_2184_000005.tmp not found)
file C:\Users\zsong98\AppData\Local\Temp\ST_2184_000005.tmp saved as .dta format

.         restore

.         * and drop the id_stores that have been exactly matched
.         bysort id_store: egen exact_matched = max(exact) 
(1,082,354 missing values generated)

.         sum lat_diff long_diff if exact == 1 // get a sense of how close (lat-long) t
> he exact matches are 

    Variable |        Obs        Mean    Std. dev.       Min        Max
-------------+---------------------------------------------------------
    lat_diff |      1,154    .0024299    .0086476          0   .1151123
   long_diff |      1,154    .0032747    .0139589          0   .3391037

.         drop if exact_matched == 1      
(63,888 observations deleted)

.         
. *** fuzzy matches based on distances
.         ustrdist address addresbr, gen(addresdist)

.         gsort citybr id_store addresdist

.         order addresdist address addresbr bank_name namehcr namefull *_diff

.         
.         * keep only Levenstein distances smaller than 10 ones 
.         drop if addresdist > 10 
(946,117 observations deleted)

.         
.         // note that for the exact matches, the lat-long differences are around 0.002
> 2 and 0.0031
. 
.         * 1. get string distances between bank_name (advan) and namehcr/namefull (SOD
> )
.                 replace namefull = subinstr(namefull, ", national association", "", .
> )  
(65,626 real changes made)

.                 ustrdist bank_name namehcr, gen(banknamedist1)

.                 ustrdist bank_name namefull, gen(banknamedist2)

.                 ustrdist dba namehcr, gen(banknamedist3)

.                 ustrdist dba namefull, gen(banknamedist4)

.                 egen bankname_dist = rowmin(banknamedist1 banknamedist2 banknamedist3
>  banknamedist4)

.                 drop banknamedist*

.                 * manually check for a threshold that shows that bank names are the s
> ame
.                 gsort citybr id_store bankname_dist

.                 * also keep only the closest bank names for each unique store 
.                 bysort id_store (bankname_dist): keep if _n == 1
(124,458 observations deleted)

.                 drop if bankname_dist > 5               
(5,931 observations deleted)

.         
.         * 2. now check the lat-long coordinates and addresses to see if we have good 
> matches    
.                 order id_store uninumbr zip zipbr *_diff

.                 
.                 drop if addresdist > 3
(4,529 observations deleted)

.                 drop if lat_diff > 0.002 | long_diff > 0.002 // here we are really co
> nservative as there are also pretty good matchings if we take lat/long_diff to be aro
> und 0.002. 
(837 observations deleted)

.                 gen fuzzy = 1 

.                 
. *** merge exact and fuzzy match results together
.         append using "`exact_city'"

.         
.         * order and keep variables 
.         keep bank_name name* address addresbr zipbr id_store uninumbr store_lat store
> _lon sims_* citybr state exact fuzzy 

.         replace exact = 0 if exact >=.
(482 real changes made)

.         replace fuzzy = 0 if fuzzy >=.
(1,136 real changes made)

.         
.         order id_store uninumbr 

.                 
.         save "$datadir/advan_sod_crosswalk_city", replace
file /Users/zsong98/Dropbox (Chicago Booth)/Bank Foot Traffic/data/source
    data/advan_sod_crosswalk_city.dta saved

.         * within each duplicated match from uninumbr to id_store, keep only the exact
>  matched ones
.         bysort uninumbr (exact): keep if _n == 1
(11 observations deleted)

.         * note that there are still a few duplicates due to duplicated unibranch 
.         duplicates tag id_store, gen(dup)

Duplicates in terms of id_store

.         tab dup  

        dup |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      1,599       99.50       99.50
          1 |          8        0.50      100.00
------------+-----------------------------------
      Total |      1,607      100.00

.         * but looking over the duplicates shows that id_store is correctly matched
.         * to each branch --
.         
.         append using "$datadir/advan_sod_crosswalk"

.         save "$datadir/advan_sod_crosswalk_full", replace
file /Users/zsong98/Dropbox (Chicago Booth)/Bank Foot Traffic/data/source
    data/advan_sod_crosswalk_full.dta saved

.         
. *** get unmatched sample after having matched on zip and city for merge
.         use "$datadir/advan_sod_crosswalk_full", clear

.         duplicates drop id_store, force

Duplicates in terms of id_store

(96 observations deleted)

.         merge 1:1 id_store using "$datadir/advan/t2/stores.dta"

    Result                      Number of obs
    -----------------------------------------
    Not matched                        14,459
        from master                         0  (_merge==1)
        from using                     14,459  (_merge==2)

    Matched                            34,189  (_merge==3)
    -----------------------------------------

.         keep if _merge == 2
(34,189 observations deleted)

.         drop _merge 

.         keep id_store address bank_name store_* city state ticker-country_code dba

.         save "$datadir/unmatched_advan_branches.dta", replace
file /Users/zsong98/Dropbox (Chicago Booth)/Bank Foot Traffic/data/source
    data/unmatched_advan_branches.dta saved

. ********************************************************************************
. capture log close
